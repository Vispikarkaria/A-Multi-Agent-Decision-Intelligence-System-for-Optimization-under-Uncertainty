{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7335f34",
   "metadata": {},
   "source": [
    "\n",
    "# LLM Uncertainty Quantification Notebook\n",
    "\n",
    "This notebook collects four complementary techniques that can be applied to large language models (LLMs) to reason about prediction uncertainty without depending on any specific vendor API. We mock some LLM outputs so that each method has deterministic, reproducible inputs.\n",
    "\n",
    "**Methods covered**\n",
    "1. Token log-probability aggregation → perplexity bands\n",
    "2. Predictive entropy over the next-token distribution\n",
    "3. Self-consistency sampling and agreement rate\n",
    "4. Semantic dispersion across samples via embedding/similarity space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import difflib\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Mock log-probabilities for 5 responses, each with 8 tokens (natural log space)\n",
    "token_logprobs = -rng.gamma(shape=2.5, scale=0.5, size=(5, 8))\n",
    "\n",
    "# Mock probability distribution for the next token after a shared prefix\n",
    "next_token_probs = rng.random(12)\n",
    "next_token_probs /= next_token_probs.sum()\n",
    "token_vocab = [f\"token_{i}\" for i in range(len(next_token_probs))]\n",
    "\n",
    "# Mock completions for a reasoning-style prompt\n",
    "sample_completions = [\n",
    "    \"The minimum cost occurs when x0 = 2.1 and x1 = 4.0.\",\n",
    "    \"Optimality is achieved at x0=2.0, x1=4.0 with minimal fuel usage.\",\n",
    "    \"We find a feasible plan near x0=6.2, x1=1.5 but it violates energy.\",\n",
    "    \"The minimum cost occurs when x0 = 2.1 and x1 = 4.0.\",\n",
    "    \"Solution favors x0≈1.9, x1≈4.2 to meet demand.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e13bc9",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Token Log-Probabilities → Perplexity Bands\n",
    "\n",
    "Language models expose token-level log-probabilities. Aggregating them gives the negative log-likelihood (cross-entropy) of a response. Higher cross-entropy (and thus higher perplexity) signals lower confidence. This metric can be tracked per sample or bucketed into qualitative bands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_cross_entropy = -token_logprobs.mean(axis=1)  # lower is better\n",
    "perplexity = np.exp(avg_cross_entropy)\n",
    "summary_df = pd.DataFrame({\n",
    "    \"sample_id\": [f\"S{i}\" for i in range(len(perplexity))],\n",
    "    \"avg_cross_entropy\": avg_cross_entropy,\n",
    "    \"perplexity\": perplexity,\n",
    "})\n",
    "summary_df[\"band\"] = pd.cut(\n",
    "    summary_df.perplexity,\n",
    "    bins=[0, 1.5, 2.5, np.inf],\n",
    "    labels=[\"confident\", \"medium\", \"high-uncertainty\"],\n",
    ")\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cfde6",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Predictive Entropy of the Next-Token Distribution\n",
    "\n",
    "For generative decoding, the entropy of the pending next-token distribution captures how peaked or flat the model is. Lower entropy implies the model strongly prefers one continuation, whereas higher entropy indicates uncertainty or multiple plausible branches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c067ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_probs = np.log(next_token_probs + 1e-12)\n",
    "entropy_nats = -np.sum(next_token_probs * log_probs)\n",
    "entropy_bits = entropy_nats / np.log(2)\n",
    "\n",
    "df_entropy = pd.DataFrame({\n",
    "    \"token\": token_vocab,\n",
    "    \"probability\": next_token_probs,\n",
    "    \"contribution\": -next_token_probs * log_probs,\n",
    "}).sort_values(\"probability\", ascending=False)\n",
    "\n",
    "print(f\"Predictive entropy: {entropy_bits:.3f} bits\")\n",
    "df_entropy.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58b8d1",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Self-Consistency Sampling and Agreement Rate\n",
    "\n",
    "Querying the LLM multiple times and measuring how often the answers agree yields an empirical uncertainty estimate. Agreement can be exact-match, fuzzy, or task-specific (e.g., numeric tolerance). Low agreement implies epistemic uncertainty due to reasoning instability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85045a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_answer(text: str) -> str:\n",
    "    text = text.lower().strip()\n",
    "    text = text.replace('≈', '~').replace('~', '')\n",
    "    return text\n",
    "\n",
    "normalized = [normalize_answer(o) for o in sample_completions]\n",
    "counter = Counter(normalized)\n",
    "most_common_answer, freq = counter.most_common(1)[0]\n",
    "agreement_ratio = freq / len(sample_completions)\n",
    "\n",
    "print(f\"Most common answer (normalized): {most_common_answer}\")\n",
    "print(f\"Agreement ratio: {agreement_ratio:.2f}\")\n",
    "print(f\"Epistemic uncertainty proxy (1 - agreement): {1 - agreement_ratio:.2f}\")\n",
    "\n",
    "Counter(sample_completions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27313254",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Semantic Dispersion via Similarity Matrix\n",
    "\n",
    "Instead of simple agreement, compute pairwise similarity (lexical or embedding-based). The mean similarity reflects how tightly clustered the responses are; $1 - \text{mean similarity}$ behaves like an uncertainty score and highlights when completions diverge semantically even if wording differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1eb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lexical_similarity(a: str, b: str) -> float:\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "N = len(sample_completions)\n",
    "S = np.eye(N)\n",
    "for i, j in combinations(range(N), 2):\n",
    "    sim = lexical_similarity(sample_completions[i], sample_completions[j])\n",
    "    S[i, j] = S[j, i] = sim\n",
    "\n",
    "upper = S[np.triu_indices(N, k=1)]\n",
    "mean_similarity = upper.mean()\n",
    "uncertainty_score = 1 - mean_similarity\n",
    "\n",
    "print(f\"Mean similarity: {mean_similarity:.3f}\")\n",
    "print(f\"Semantic dispersion (uncertainty): {uncertainty_score:.3f}\")\n",
    "\n",
    "pd.DataFrame(S, columns=[f\"S{i}\" for i in range(N)], index=[f\"S{i}\" for i in range(N)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
